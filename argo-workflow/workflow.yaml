apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: openfood-workflow-v1-
spec:
  entrypoint: main
  arguments:
    parameters:
      - name: aws-access-id
        value: "changeMe"
      - name: aws-secret-key
        value: "changeMe"
      - name: aws-session-token
        value: "changeMe"
      - name: aws-default-region
        value: "us-east-1"
      - name: aws-s3-endpoint
        value: "minio.lab.sspcloud.fr"
       # The mlflow tracking server is responsable to log the hyper-parameter and model metrics,
       # You can create it inside the datalab, and copy the url. Below is an example
       # https://pengfei-mlflow-7841853311341079041-mlflow-ihm.kub.sspcloud.fr/
      - name: mlflow-tracking-uri
        value: 'changeMe'
      - name: mlflow-experiment-name
        value: "openfood"
      - name: mlflow-s3-url
        value: "https://minio.lab.sspcloud.fr"
      - name: model-training-conf-list
        value: |
          [
            { "lr": 2e-4, "nepochs": 1 },
            { "lr": 3e-4, "nepochs": 1 },
            { "lr": 4e-4, "nepochs": 1 },
            { "lr": 5e-4, "nepochs": 1 }
          ]
  # Create a pvc for the workflow
  volumeClaimTemplates:
    - metadata:
        name: workflow-tmp
      spec:
        accessModes: [ "ReadWriteOnce" ]
        resources:
          requests:
            storage: 10Gi

  templates:
    #############################################################################################
    #################### main template for planning dag of the pipeline #########################
    #############################################################################################
    - name: main
      dag:
        tasks:
          # task 0: load code source and data
          - name: load-code-and-data
            template: load-code-and-data-wt
          # task 1: train model with given params
          - name: train-model-with-given-params
            dependencies: [ load-code-and-data ]
            template: run-model-training-wt
            arguments:
              parameters:
                - name: lr
                  value: "{{item.lr}}"
                - name: nepochs
                  value: "{{item.nepochs}}"
              # pass the inputs to the step "withParam"
            withParam: "{{workflow.parameters.model-training-conf-list}}"
    ####################################################################################################################
    #################### task template for implementing the logic of each task of the pipeline #########################
    ####################################################################################################################
    # worker template for task-0 load code
    - name: load-code-and-data-wt
      inputs:
        artifacts:
          # Check out the master branch of the argo repo and place it at /src
          # revision can be anything that git checkout accepts: branch, commit, tag, etc.
          - name: code
            path: /mnt/bin
            git:
              repo: https://github.com/pengfei99/openfood.git
              revision: "main"
      container:
        image: liupengfei99/openfood-cpu-worker:latest
        command: [ sh, -c ]
        args: [ "mkdir -p /mnt/openfood_data;
                 python /mnt/bin/siamesenetwork/main.py -c /mnt/bin/siamesenetwork/config.yml;
                 ls -l /mnt/bin /mnt/openfood_data" ]
        env:
          - name: AWS_SECRET_ACCESS_KEY
            value: "{{workflow.parameters.aws-secret-key}}"
          - name: AWS_DEFAULT_REGION
            value: "{{workflow.parameters.aws-default-region}}"
          - name: AWS_S3_ENDPOINT
            value: "{{workflow.parameters.aws-s3-endpoint}}"
          - name: AWS_SESSION_TOKEN
            value: "{{workflow.parameters.aws-session-token}}"
          - name: AWS_ACCESS_KEY_ID
            value: "{{workflow.parameters.aws-access-id}}"
        volumeMounts:
          - name: workflow-tmp
            mountPath: /mnt

    # worker template for task-1 train model
    - name: run-model-training-wt
      inputs:
        parameters:
          - name: lr
          - name: nepochs
      container:
        image: liupengfei99/openfood-cpu-worker:latest
        command: [sh, -c]
        args: ["python /mnt/bin/siamesenetwork/run_pretrained_embedding_with_mlflow.py
                -c /mnt/bin/siamesenetwork/config.yml -n {{inputs.parameters.nepochs}} -l {{inputs.parameters.lr}}"]
        env:
          - name: AWS_SECRET_ACCESS_KEY
            value: "{{workflow.parameters.aws-secret-key}}"
          - name: AWS_DEFAULT_REGION
            value: "{{workflow.parameters.aws-default-region}}"
          - name: AWS_S3_ENDPOINT
            value: "{{workflow.parameters.aws-s3-endpoint}}"
          - name: AWS_SESSION_TOKEN
            value: "{{workflow.parameters.aws-session-token}}"
          - name: AWS_ACCESS_KEY_ID
            value: "{{workflow.parameters.aws-access-id}}"
          - name: MLFLOW_TRACKING_URI
            value: "{{workflow.parameters.mlflow-tracking-uri}}"
          - name: MLFLOW_EXPERIMENT_NAME
            value: "{{workflow.parameters.mlflow-experiment-name}}"
          - name: MLFLOW_S3_ENDPOINT_URL
            value: "{{workflow.parameters.mlflow-s3-url}}"
        volumeMounts:
          - name: workflow-tmp
            mountPath: /mnt

